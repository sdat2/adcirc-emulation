{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c14fd2e",
   "metadata": {},
   "source": [
    "# 6D Emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63718fe2",
   "metadata": {},
   "source": [
    "###  Load Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf0cbcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T15:05:35.957997Z",
     "start_time": "2022-11-22T15:05:35.918757Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convenient jupyter setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ed237e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T15:17:49.925480Z",
     "start_time": "2022-11-22T15:17:49.854489Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from frozendict import frozendict\n",
    "import GPy\n",
    "from GPy import kern\n",
    "from GPy.kern import Linear, RBF, Matern32, Matern52\n",
    "from GPy.models import GPRegression\n",
    "from emukit.bayesian_optimization.acquisitions import ExpectedImprovement\n",
    "from emukit.bayesian_optimization.loops import BayesianOptimizationLoop\n",
    "from emukit.experimental_design.experimental_design_loop import ExperimentalDesignLoop\n",
    "from emukit.model_wrappers import SimpleGaussianProcessModel, GPyModelWrapper\n",
    "from emukit.core.initial_designs.latin_design import LatinDesign\n",
    "from emukit.experimental_design.acquisitions import ModelVariance\n",
    "from emukit.bayesian_optimization.acquisitions import (\n",
    "    MaxValueEntropySearch,\n",
    "    ProbabilityOfImprovement,\n",
    "    ExpectedImprovement,\n",
    ")\n",
    "from emukit.core import ParameterSpace, ContinuousParameter\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import imageio as io\n",
    "from adcircpy.outputs import Maxele\n",
    "from sithom.plot import plot_defaults, label_subplots\n",
    "from sithom.time import timeit\n",
    "from sithom.place import Point\n",
    "from sithom.misc import in_notebook\n",
    "from src.models.generation import ImpactSymmetricTC, Holland08\n",
    "from src.constants import DATA_PATH, FIGURE_PATH, NEW_ORLEANS, NO_BBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c0a8b06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T15:30:32.312135Z",
     "start_time": "2022-11-22T15:30:32.207593Z"
    }
   },
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def indices_in_bbox(lon, lat):\n",
    "    return (\n",
    "        lon > NO_BBOX.lon[0]\n",
    "        and lon < NO_BBOX.lon[1]\n",
    "        and lat > NO_BBOX.lat[0]\n",
    "        and lat < NO_BBOX.lat[1]\n",
    "    )\n",
    "\n",
    "@np.vectorize\n",
    "def real_func(angle: float, position: float, output_direc: str) -> float:\n",
    "    point = Point(NEW_ORLEANS.lon + position, NEW_ORLEANS.lat)\n",
    "    if os.path.exists(output_direc):\n",
    "        shutil.rmtree(output_direc)\n",
    "    ImpactSymmetricTC(\n",
    "        point=point,\n",
    "        output_direc=output_direc,\n",
    "        symetric_model=Holland08(),\n",
    "        angle=angle,\n",
    "    ).run_impact()\n",
    "    path = os.path.join(output_direc, \"maxele.63.nc\")\n",
    "    maxele = Maxele(path, crs=\"EPSG:4326\")\n",
    "    index_set = 27\n",
    "    indices = indices_in_bbox(maxele.x, maxele.y)\n",
    "    return maxele.values[indices][index_set]\n",
    "\n",
    "@np.vectorize\n",
    "def fake_func(angle: float, position: float, output_direc: str) -> float:\n",
    "    return 0.0\n",
    "\n",
    "class Emulation():\n",
    "    def __init__(\n",
    "        self,\n",
    "        seed=0,\n",
    "        init_num=40,\n",
    "        active_num=30,\n",
    "        indices=100,\n",
    "        acqusition_class=ExpectedImprovement,\n",
    "        loop_class=BayesianOptimizationLoop,\n",
    "        kernel_class=RBF,\n",
    "        x1_range=[-90, 90],\n",
    "        x2_range=[-2, 3.2],\n",
    "        path=\"emu_angle_position\",\n",
    "        debug=\n",
    "    ) -> None:\n",
    "        self.seed = seed\n",
    "        np.random.seed(seed)\n",
    "        self.indices = indices\n",
    "        x1_range, x2_range = self.to_gp_scale(np.array(x1_range), np.array(x2_range))\n",
    "        x1_range = x1_range.tolist()\n",
    "        x2_range = x2_range.tolist()\n",
    "        self.ap = ContinuousParameter(\"a_param\", *x1_range)\n",
    "        self.bp = ContinuousParameter(\"b_param\", *x2_range)\n",
    "        self.space = ParameterSpace([self.ap, self.bp])\n",
    "        self.design = LatinDesign(self.space)\n",
    "        self.init_num = init_num\n",
    "        self.active_num = active_num\n",
    "        self.figure_path = os.path.join(FIGURE_PATH, path)\n",
    "        self.data_path = os.path.join(DATA_PATH, path)\n",
    "        self.call_number = 0\n",
    "\n",
    "        for path in [self.figure_path, self.data_path]:\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "\n",
    "        # run initial data.\n",
    "        self.init_x_data = self.design.get_samples(self.init_num).astype(\"float32\")\n",
    "        self.init_y_data = self.func(self.init_x_data)\n",
    "\n",
    "        # Fit initial GPyRegression\n",
    "        self.model_gpy = GPRegression(\n",
    "            self.init_x_data,\n",
    "            self.init_y_data.reshape(len(self.init_y_data), 1),\n",
    "            kernel_class(2, 1),\n",
    "        )\n",
    "        self.model_gpy.optimize()\n",
    "\n",
    "        # active_learning - make acquisition file & loop.\n",
    "        self.model_emukit = GPyModelWrapper(self.model_gpy)\n",
    "        if acqusition_class is MaxValueEntropySearch:\n",
    "            self.acquisition_function = acqusition_class(\n",
    "                model=self.model_emukit, space=self.space\n",
    "            )\n",
    "        else:\n",
    "            self.acquisition_function = acqusition_class(model=self.model_emukit)\n",
    "\n",
    "        self.loop = loop_class(\n",
    "            model=self.model_emukit,\n",
    "            space=self.space,\n",
    "            acquisition=self.acquisition_function,\n",
    "            batch_size=1,\n",
    "        )\n",
    "\n",
    "        # get ready for active learning.\n",
    "        self.active_x_data = np.array([[np.nan, np.nan]])\n",
    "        self.active_y_data = np.array([[np.nan]])\n",
    "\n",
    "        # make initial plot\n",
    "        self.plot()\n",
    "        plt.savefig(os.path.join(self.figure_path, f\"0.png\"))\n",
    "        if in_notebook():\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.clf()\n",
    "\n",
    "        for i in range(1, active_num + 1):\n",
    "            print(i)\n",
    "            self.run_loop(1)\n",
    "            self.plot()\n",
    "            plt.savefig(os.path.join(self.figure_path, f\"{i}.png\"))\n",
    "            if in_notebook():\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.clf()\n",
    "\n",
    "        with io.get_writer(f\"{self.figure_path}.gif\", mode=\"I\", duration=0.5) as writer:\n",
    "            for file_name in [\n",
    "                os.path.join(self.figure_path, f\"{i}.png\")\n",
    "                for i in range(self.active_num + 1)\n",
    "            ]:\n",
    "                image = io.imread(file_name)\n",
    "                writer.append_data(image)\n",
    "        writer.close()\n",
    "        self.save_data()\n",
    "\n",
    "    def save_data(self):\n",
    "        init_x, init_y = self.init_data()\n",
    "        active_x, active_y = self.active_data()\n",
    "        ds = xr.Dataset(\n",
    "            data_vars=dict(\n",
    "                init_x=([\"inum\", \"var\"], init_x),\n",
    "                init_y=([\"inum\"], init_y[:, 0]),\n",
    "                active_x=([\"anum\", \"var\"], active_x),\n",
    "                active_y=(\"anum\", active_y[:, 0]),\n",
    "            ),\n",
    "            coords=dict(\n",
    "                var=([\"var\"], [\"x1\", \"x2\"]),\n",
    "            ),\n",
    "            attrs=dict(description=\"Training Data\"),\n",
    "        )\n",
    "        file_name = os.path.join(self.data_path, \"data.nc\")\n",
    "        if not os.path.exists(file_name):\n",
    "            ds.to_netcdf(file_name)\n",
    "        else:\n",
    "            print(\"File Already Exists!\")\n",
    "\n",
    "    def run_loop(self, new_iterations):\n",
    "        self.loop.run_loop(self.func, new_iterations)\n",
    "        self.active_x_data = self.loop.loop_state.X[len(self.init_x_data) :]\n",
    "        self.active_y_data = self.loop.loop_state.Y[len(self.init_x_data) :]\n",
    "\n",
    "    def init_data(self):\n",
    "        return (\n",
    "            self.merge(*self.to_real_scale(*self.split(self.init_x_data))),\n",
    "            -self.init_y_data,\n",
    "        )\n",
    "\n",
    "    def active_data(self):\n",
    "        return (\n",
    "            self.merge(*self.to_real_scale(*self.split(self.active_x_data))),\n",
    "            -self.active_y_data,\n",
    "        )\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"seed = {self.seed}, init_num = {self.init_num}, active_num = {self.active_num}\"\n",
    "\n",
    "    def to_gp_scale(self, x1, x2):\n",
    "        return (x1 + 60) / 10, (x2 - 0.6) / 0.5\n",
    "\n",
    "    def to_real_scale(self, x1, x2):\n",
    "        return x1 * 10 - 60, x2 / 2 + 0.6\n",
    "\n",
    "    def merge(self, x1, x2):\n",
    "        return np.concatenate(\n",
    "            [x1.reshape(*x1.shape, 1), x2.reshape(*x2.shape, 1)], axis=-1\n",
    "        )\n",
    "\n",
    "    def split(self, data):\n",
    "        shape = data.shape\n",
    "        if len(shape) == 2:\n",
    "            return data[:, 0], data[:, 1]\n",
    "        elif len(shape) == 3:\n",
    "            return data[:, :, 0], data[:, :, 1]\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def ob_func(self, angle: np.array, position: float) -> float:\n",
    "        # print(angle, position)\n",
    "        num = len(angle)\n",
    "        output_direc = [\n",
    "            os.path.join(self.data_path, str(self.call_number + i)) for i in range(num)\n",
    "        ]\n",
    "        self.call_number += num\n",
    "        return -smash_func(angle, position, output_direc)\n",
    "\n",
    "    def func(self, data) -> float:\n",
    "        output = self.ob_func(*self.to_real_scale(*self.split(data)))\n",
    "        return output.reshape(len(output), 1)\n",
    "\n",
    "    def learnt_function(self, x1, x2):\n",
    "        mean, var = self.model_emukit.predict(self.merge(*self.to_gp_scale(x1, x2)))\n",
    "        return -mean, np.std(var)\n",
    "\n",
    "    def plot(self) -> None:\n",
    "        a_indices = np.linspace(self.ap.min, self.ap.max, num=self.indices)\n",
    "        b_indices = np.linspace(self.bp.min, self.bp.max, num=self.indices)\n",
    "        a_indices, b_indices = self.to_real_scale(a_indices, b_indices)\n",
    "        a_mesh, b_mesh = np.meshgrid(a_indices, b_indices)\n",
    "        length = len(a_indices) * len(b_indices)\n",
    "        a_array = a_mesh.ravel()\n",
    "        b_array = b_mesh.ravel()\n",
    "        comb_array = np.zeros([length, 2])\n",
    "        comb_array[:, 0] = a_array[:]\n",
    "        comb_array[:, 1] = b_array[:]\n",
    "        comb_array_gp = self.merge(*self.to_gp_scale(*self.split(comb_array)))\n",
    "\n",
    "        # Evaluate Gaussian Process\n",
    "        mean, var = self.model_emukit.predict(comb_array_gp)\n",
    "        mean_mesh = -mean[:, 0].reshape(self.indices, self.indices)\n",
    "        std_mesh = np.sqrt(var[:, 0]).reshape(self.indices, self.indices)\n",
    "        # Evaluate Acquisition Function\n",
    "        aq_mesh = self.acquisition_function.evaluate(comb_array_gp).reshape(\n",
    "            self.indices, self.indices\n",
    "        )\n",
    "\n",
    "        # Set up plot\n",
    "        plot_defaults()\n",
    "        fig, axs = plt.subplots(\n",
    "            2, 2, sharex=True, sharey=True\n",
    "        )\n",
    "        label_subplots(axs, override=\"outside\")\n",
    "\n",
    "        ax = axs[0, 1]\n",
    "        ax.set_title(\"Acq. Func.\")\n",
    "        im = ax.contourf(a_mesh, b_mesh, aq_mesh)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        fig.colorbar(im, cax=cax, orientation=\"vertical\")\n",
    "\n",
    "        ax = axs[0, 0]\n",
    "        init_x, init_y = self.init_data()\n",
    "        active_x, active_y = self.active_data()\n",
    "        im = ax.scatter(\n",
    "            init_x[:, 0],\n",
    "            init_x[:, 1],\n",
    "            c=init_y,\n",
    "            marker=\"x\",\n",
    "            label=\"original data points\",\n",
    "        )\n",
    "        ax.scatter(\n",
    "            active_x[:, 0],\n",
    "            active_x[:, 1],\n",
    "            c=active_y,\n",
    "            marker=\"+\",\n",
    "            label=\"new data points\",\n",
    "        )\n",
    "        divider = make_axes_locatable(ax)\n",
    "        ax.set_title(\"Samples\")\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        fig.colorbar(im, cax=cax, orientation=\"vertical\")\n",
    "        ax.set_ylabel(\"Position [$^{\\circ}$E]\")\n",
    "\n",
    "        ax = axs[1, 0]\n",
    "        ax.set_title(\"Prediction Mean\")\n",
    "        im = ax.contourf(a_mesh, b_mesh, mean_mesh)  # , vmin=0, vmax=5.6)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        fig.colorbar(im, cax=cax, orientation=\"vertical\")\n",
    "        ax.set_ylabel(\"Position [$^{\\circ}$E]\")\n",
    "        ax.set_xlabel(\"Bearing [$^{\\circ}$]\")\n",
    "        ax = axs[1, 1]\n",
    "        ax.set_title(\"Pred. Std. Dev. \")\n",
    "        im = ax.contourf(a_mesh, b_mesh, std_mesh)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        fig.colorbar(im, cax=cax, orientation=\"vertical\")\n",
    "        ax.set_xlabel(\"Bearing [$^{\\circ}$]\")\n",
    "\n",
    "\n",
    "def poi():\n",
    "    Emulation(\n",
    "        acqusition_class=ProbabilityOfImprovement, path=\"emulation_angle_pos_poi\"\n",
    "    )\n",
    "\n",
    "\n",
    "def poi_long():\n",
    "    Emulation(\n",
    "        acqusition_class=ProbabilityOfImprovement,\n",
    "        path=\"emulation_angle_pos_poi_long\",\n",
    "        init_num=100,\n",
    "        active_num=50,\n",
    "    )\n",
    "\n",
    "\n",
    "def mves():\n",
    "    Emulation(\n",
    "        acqusition_class=MaxValueEntropySearch, path=\"emulation_angle_pos_mves\"\n",
    "    )\n",
    "\n",
    "\n",
    "def inp_diff():\n",
    "    Emulation(\n",
    "        path=\"emulation_angle_pos_big\",\n",
    "        seed=20,\n",
    "        init_num=100,\n",
    "        active_num=30,\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70cc5c35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T18:49:34.752415Z",
     "start_time": "2022-11-22T18:49:34.709566Z"
    }
   },
   "outputs": [],
   "source": [
    "def param(updates):\n",
    "    defaults = {\n",
    "        # Trajectory\n",
    "        \"angle\": 0.0, # degrees from North\n",
    "        \"speed\": 7.71, # m s**-1\n",
    "        \"point_east\": 0.6, # degrees East of New Orleans\n",
    "        # Radial Profile of Tropical Cyclone - Holland Hurricane Parameters\n",
    "        \"rmax\": 40744.0, # meters\n",
    "        \"pc\": 92800.0, # Pa\n",
    "        \"vmax\": 54.01667, # m s**-1\n",
    "        \"xn\": 1.1249, # dimensionless\n",
    "    }\n",
    "    # no surprises\n",
    "    assert np.all([x in defaults.keys() for x in updates.keys()])\n",
    "\n",
    "    output = defaults.copy()\n",
    "\n",
    "    for key in updates:\n",
    "        output[key] = updates[key]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def holliday(updates):\n",
    "    assert \"pc\" in updates.keys()\n",
    "    updates[\"vmax\"] = vmax_from_pressure_holliday(92800)\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fb01c42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T18:50:11.795295Z",
     "start_time": "2022-11-22T18:50:11.751986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angle': 0.0,\n",
       " 'speed': 7.71,\n",
       " 'point_east': 0.6,\n",
       " 'rmax': 40744.0,\n",
       " 'pc': 92900.0,\n",
       " 'vmax': 54.01667,\n",
       " 'xn': 1.1249}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param(holliday({\"angle\":0.0, \"pc\": 92900.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f31965c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T18:47:51.281186Z",
     "start_time": "2022-11-22T18:47:51.050869Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.models.generation import vmax_from_pressure_holliday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b586aa8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T18:48:10.552201Z",
     "start_time": "2022-11-22T18:48:10.507040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.01667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmax_from_pressure_holliday(92800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c4688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
